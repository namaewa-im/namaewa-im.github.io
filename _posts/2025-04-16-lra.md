---
title: "Long Range Arena: A Benchmark for Efficient Transformers"
date: 2025-04-16
categories: [PaperReview, LRA, Transformer]
tags: [LRA, Efficient Transformer, Benchmark, Sequence Modeling]
---

> 논문 링크: [https://arxiv.org/abs/2011.04006](https://arxiv.org/abs/2011.04006)  
> 코드: [https://github.com/google-research/long-range-arena](https://github.com/google-research/long-range-arena)  
> 작성자: Google Research / DeepMind ({yitay, dehghani}@google.com)

## Abstract

- 트랜스포머는 quadratic self-attention complexity 때문에 시퀀스 길이 방향으로 잘 확장되지 않음 
- 이 문제를 해결하기 위해 더 효율적이고 빠른 트랜스포머의 변형이 제안되고 있지만 명확한 평가 기준이 없음
-  따라서 본 논문은 모델의 long context scenario를 학습 품질을 평가하는 체계적이고 통일된 벤치마크인 LRA를 제안
-  LRA는 1K~16K에 달하는 토큰을 가진 text, natural, synthetic images, mathematical expressions(requiring similarity, structural, visual-spatical reasoning)에 대한 작업을 정의함
-  10종의 well-established 트랜스포머 모델에 대해 LRA 학습 성능을 평가
-  이 논문은 모델이 long-range data의 모델링을 더 잘 이해할 수 있는 길을 열고 해당 방향으로의 더 많은 연구를 촉진하며, 앞으로의 모델이 해결해야 할 새로운 도전 과제를 제시하는 역할을 함

## Introduction

- Transformer의 self-attention 연산은 시퀀스 길이에 따라 메모리/연산 복잡도가 O(n²)로 증가하는 구조적 한계가 있음  
- 이를 해결하기 위해 다양한 Efficient Transformer(xformer) 구조들이 제안되었지만, 다음과 같은 문제점이 있음

### 기존 연구의 문제점

#### 1. 공정한 비교를 위한 합의된 공통의 벤치마크가 없음
- 모델마다 서로 다른 태스크와 데이터셋을 사용함
- 성능 차이가 모델 구조 때문인지 태스크 때문인지 판단이 어려움

#### 2. 장기 의존성을 평가하기에 적합하지 않은 테스트 환경
- 대부분의 기존 벤치마크는 시퀀스 길이가 짧거나, 구조적 복잡성이 낮음  
- 구조 추론이나 장거리 관계 학습 능력을 제대로 평가하지 못함

#### 3. 많은 논문에서 귀납적 편향의 효과와 사전학습의 효과를 혼동함
- 일부 모델은 구조적 특성이 좋기보다는 데이터 증강이나 사전학습을 통해 좋은 성능을 냄
- 구조의 장점을 보기 위해서는 사전학습 없이 평가할 필요가 있음

### LRA가 제안된 이유

- 긴 맥락 정보 시퀀스에 대한 장기 의존성을 학습하는 능력을 평가하는 체계적이고 통합된 기준을 제시함
- 다양한 태스크에 대해 일반적인 모델의 성능을 평가할 수 있도록 설계  
- 효율성(efficiency)뿐 아니라, 계층 구조, 시각적 종속성, 문서 간 유사성 등 다양한 구조적 특성에 대한 모델의 적합성을 비교할 수 있음

### LRA의 실험 목적과 구성 방향

- 사전학습 없이 순수한 구조 성능을 평가  
- Capability probing을 위한 태스크 구성: 모델이 계층적 구조, 공간 관계 등을 잘 학습하는지 확인  
- JAX/Flax 기반 구현체 제공으로 reproducibility 확보  
- 효율성과 메모리 사용량 측면에서도 상세한 분석 제공

## Long-Range Arena (LRA)
LRA는 다음과 같은 desiderata(≈희망사항 또는 요구조건)를 설정함

1. **Generality (일반성)**: 모든 모델은 LRA에서 정의한 작업들을 수행할 수 있어야 함
2. **Simplicity (단순성)**: 모든 작업은 단순해야하며 데이터 증강이나 사전 학습등은 허용되지 않음  
3. **Challenging (도전성)**: 해당 방향으로의 향후 연구를 장려하기 위해 개선에 여지가 있을 정도로 작업이 충분히 어려워야 함  
4. **Long inputs (긴 입력)**: 장거리 종속성을 모델링하는 것이 LRA 데이터셋의 핵심이기 때문에 입력 시퀀스의 길이가 길어야 함  
5. **Probing diverse aspects (다양한 측면의 조사)**: LRA가 정의하는 작업은 관계 및 계층적, 공간적 구조를 모델링하는 능력과 일반화 기능과 같은 모델의 다양한 측면을 조사할 수 있어야 함 
6. **Non-resource intensive and accessible (자원 집약적이지 않고 접근 가능)**: 가벼운 컴퓨팅 자원으로도 접근할 수 있도록 작업이 가볍게 설계되어야 함

---

### Task description

#### 1. ListOps
- INPUT : [MAX 4 3 [MIN 2 3] 1 0 [MEDIAN 1 5 8 9 2]] 
- OUTPUT : 5
- 괄호 구조를 파악해야 하는 10 class 분류 문제
- 시퀀스 길이: 2K

#### 2. Byte-level Text Classification (Imdb)
- Imdb dataset 사용 (Maas et al., 2011)
- 사전학습 없이 binary 분류 수행
- 시퀀스 길이: 1K

#### 3. Byte-level Document Retrieval (AAN)
- ACL Anthology Network 사용 (AAN; Radev et al., 2013)
- 두 문서를 바이트 단위로 4K씩 입력 → 총 8K
- 문서 간 관계 추론
- 시퀀스 길이: 4K

#### 4. Image Classification on sequences of pixels (CIFAR-10)
- CIFAR-10 dataset 사용 (Krizhevsky, 2009)
- 32x32 픽셀을 flatten하여 길이 1024(1K) 시퀀스
- CNN 사용 불가, 1D input으로 2D 공간 관계 학습
- 시퀀스 길이: 1K

#### 5. Pathfinder / Path-X
- Pathfinder Challenge (Linsley et al., 2018; Kim et al., 2020)
- 점 두 개가 선으로 연결되어 있는지 판단 (이진 분류)
- Pathfinder: 32x32 (1024, 1K), Path-X: 128x128 (16K)  

![pathfinder](/assets/img/lra/pathfinder.jpg){: width="50%"}

---

## Experimental Results

#### ListOps
- 최고 성능 37%, 대부분 모델은 10~30% 수준
- 효율성 중심 설계 모델 성능이 높은편, kernel 기반 모델 (Performer, Linear Transformer)은 계층적 구조 처리에 약한 경향이 있었음

#### IMDb
- 최고 65.9%
- Performer 계열이 강세
- Listops와는 반대로 빠른 커널 기반의 모델이 성능이 높은편

#### CIFAR-10
- 모델 간 큰 차이 없이 비슷한 성능
- train 정확도 높지만 test 성능 낮음 → 오버피팅 심함

#### Pathfinder / Path-X
- Pathfinder: 평균 72%, Performer 77.05%
- Path-X: 모든 모델이 50% 이하 (랜덤 수준)

### Result

![Table1](/assets/img/lra/table1.jpg)  
<!-- ![Table2](/assets/img/lra/table2.jpg)   -->

- 결론: 만능 모델은 없음
- BigBird는 가장 **일관된 성능** 으로 평균 성능 가장 우수
- Performer, Linformer는 **빠르고 가볍지만** ListOps 성능 때문에 평균 성능 낮음
- x축은 속도, y축은 성능, 원의 크기는 메모리 사용량을 나타냄  

![figure3](/assets/img/lra/figure3.jpg)  


---

## 데이터셋 다운로드 방법

> 공식 가이드: [https://github.com/google-research/long-range-arena#dataset-setup](https://github.com/google-research/long-range-arena#dataset-setup)
> ![datasetup](/assets/img/lra/datasetup.jpg)

### lra_release

> `lra_release.gz` 압축파일 기준 약 7.7GB

```
lra_release/lra_release/
├── listops-1000
├── pathfinder32
├── pathfinder64
├── pathfinder128
├── pathfinder256
└── tsv_data
```
- listops-1000: Listops
- pathfinder32: Pathfinder
- pathfinder128: Path-X
- tsv_data: aan
- imdb, cifar-10은 tensorflow dataset에 있으므로 별도로 다운로드하지 않아도 됨 
- 학습 파이프라인은 각 작업의 input_pipeline.py와 train.py 참고

```
listops-1000/
├── basic_test.tsv
├── basic_train.tsv
└── basic_val.tsv
```
![listops-1000 folder](/assets/img/lra/listops_folder.jpg)

```
tsv_data/
├── new_aan_pairs.eval.tsv
├── new_aan_pairs.test.tsv
├── new_aan_pairs.test_sample.tsv
└── new_aan_pairs.train.tsv
```
![aan folder](/assets/img/lra/aan_folder.jpg)
