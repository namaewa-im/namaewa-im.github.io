---
title: "Long Range Arena: A Benchmark for Efficient Transformers"
date: 2025-04-16
categories: [PaperReview, LRA, Transformer]
tags: [LRA, Efficient Transformer, Benchmark, Sequence Modeling]
---

> 논문 링크: [https://arxiv.org/abs/2011.04006](https://arxiv.org/abs/2011.04006)  
> 코드: [https://github.com/google-research/long-range-arena](https://github.com/google-research/long-range-arena)  
> 작성자: Google Research / DeepMind ({yitay, dehghani}@google.com)

트랜스포머는 시퀀스 길이 방향으로 잘 확장되지 않는다. Quadratic self-attention complexity 때문이다. 이 문제를 해결하기 위해 더 효율적이고 빠른 트랜스포머의 변형이 제안되고 있으며, 기본 트랜스포머 모델보다 우수하거나 그와 비슷한 모델 품질을 주장한다. 하지만 이러한 모델을 평가하는 방법에 대한 합의가 이전까지 없었으므로, 이 논문은 long context scenario(장기 맥락 시나리오, 맥락 정보가 들어간 긴 시계열 처리를 위한 데이터)에서 모델의 품질을 평가하는 체계적이고 통일된 벤치마크인 LRA를 제안한다. LRA는 1K~16K에 달하는 토큰을 가진 text, natural, synthetic images, mathematical expressions(requiring similarity, structural, visual-spatical reasoning) 에 대한 작업을 정의한다. 10종의 well-established 트랜스포머 모델을 평가하여 이러한 종류의 트랜스포머 모델을 더 잘 이해할 수 있는 길을 열고 해당 방향으로의 더 많은 연구를 촉진하며 해결해야 할 새로운 도전 과제를 제시한다. 벤치마크에 대한 코드는  https://github.com/google-research/long-range-arena 에서 제공한다.

## Introduction
트랜스포머의 약점인 self-attention 내의 2차 메모리 복잡성을 해결하기 위해 많은 트랜스포머 변형 모델이 제안되었다. (일명 xformers 라고 하는) 이러한 논문의 평가 실험을 관찰한 결과,  

1. 효율적인 트랜스포머를 벤치마크하기 위해 수용 가능한 테스트 베드를 만드는 것에 대한 통일된 합의가 없다. 채택되는 작업 유형도 매우 다양하며, 모든 단일 모델은 서로 다른 작업 및 데이터셋에서 평가되기 때문에 서로 다른 모델을 비교하고 상대적인 강점과 약점을 평가하기가 어렵다.  
2. 평가에 사용되는 벤치마크가 장거리 데이터 모델링을 평가하는 데 적합한지에 대해 고려하지 않고 임의로 테스트 데이터셋을 선택하는 경우가 많다.  
3. 많은 논문에서 귀납적 편향의 효과와 사전 훈련의 이점을 혼동한다. 사전학습과 귀납적 편향에 대한 연구를 분리해야한다.  

LRA는 긴 컨텍스트 시나리오에서 추론할 수 있는 모델의 능력을 평가하는 데 초점을 맞추지만, 다양한 유형의 데이터 및 조건에 대해 아키텍처의 기능과 속성을 이해하는 데에도 관심이 있다. 따라서 LRA는 의도적으로 capability probing, 즉 특정 타고난 구조를 가진 데이터셋과 작업을 선택하도록 설계되었다. (무슨 말이냐면 특정 아키텍처가 본질적으로 계층적이거나 어떤 형태의 공간 구조를 포함하는 긴 시퀀스를 모델링할 수 있는지 아닌지 알고 싶다는 뜻) 효율적인 트랜스포머 모델에 국한되지 않고 장거리 시퀀스 모델링을 위한 모델이라면 어떤것이든 LRA가 좋은 벤치마크의 역할을 할 수 있다.  

모델의 품질 외에도 extensive한 효율성 및 메모리 사용량 분석을 통해 모델의 효율성에 대한 깊은 인사이트를 제공한다. 해당 오픈 소스는 JAX/FLAX로 작성되었다.  

## Long-Range Arena (LRA)
LRA는 다음과 같은 desiderata(≈희망사항 또는 요구조건)를 설정하였다.  

1. **Generality (일반성)**: 모든 모델은 LRA에서 정의한 작업들을 수행할 수 있어야한다.  
2. **Simplicity (단순성)**: 작업은 단순해야한다. 데이터 증강이나 사전 학습등은 허용되지 않는다.  
3. **Challenging (도전성)**: 해당 방향으로의 향후 연구를 장려하기 위해 개선에 여지가 있을 정도로 작업이 어려워야한다.  
4. **Long inputs (긴 입력)**: 장거리 종속성을 모델링하는 것이 LRA 데이터셋의 핵심이기 때문에 입력 시퀀스의 길이가 길어야한다.  
5. **Probing diverse aspects (다양한 측면의 조사)**: LRA가 정의하는 작업은 관계 및 계층적, 공간적 구조를 모델링하는 능력과 일반화 기능과 같은 모델의 다양한 측면을 조사할 수 있어야한다.  
6. **Non-resource intensive and accessible (자원 집약적이지 않고 접근 가능)**: 가벼운 컴퓨팅 자원으로도 접근할 수 있도록 가볍게 설계되어야한다.  

---

## Task

### 1. ListOps
- `INPUT : [MAX 4 3 [MIN 2 3] 1 0 [MEDIAN 1 5 8 9 2]]` → `OUTPUT : 5`
- 괄호 구조를 파악해야 하는 10-way 분류 문제
- 시퀀스 길이: 2K

### 2. Byte-level Text Classification (Imdb)
- IMDb dataset 사용 (Maas et al., 2011)
- 사전학습 없이 binary 분류 수행
- 시퀀스 길이: 1K

### 3. Byte-level Document Retrieval (AAN)
- ACL Anthology Network 사용 (AAN; Radev et al., 2013)
- 두 문서를 바이트 단위로 4K씩 입력 → 총 8K
- 문서 간 관계 추론
- 시퀀스 길이: 4K

### 4. Image Classification on sequences of pixels (CIFAR-10)
- CIFAR-10 dataset 사용 (Krizhevsky, 2009)
- 32x32 픽셀을 flatten하여 길이 1024(1K) 시퀀스
- CNN 사용 불가, 1D input으로 2D 공간 관계 학습
- 시퀀스 길이: 1K

### 5. Pathfinder / Path-X
- Pathfinder Challenge (Linsley et al., 2018; Kim et al., 2020)
- 점 두 개가 선으로 연결되어 있는지 판단 (이진 분류)
- Pathfinder: 32x32 (1024, 1K), Path-X: 128x128 (16K)  
![pathfinder](/asset/img/lra/pathfinder.jpg)

---

## Experimental Results

### ListOps
- 최고 성능 37%, 대부분 모델은 10~30% 수준
- 효율성 중심 설계 모델 성능이 높은편, kernel 기반 모델 (Performer, Linear Transformer)은 계층적 구조 처리에 약한 경향이 있었음

### IMDb
- 최고 65.9%
- Performer 계열이 강세
- Listops와는 반대로 빠른 커널 기반의 모델이 성능이 높은편

### CIFAR-10
- 모델 간 큰 차이 없이 비슷한 성능
- train 정확도 높지만 test 성능 낮음 → 오버피팅 심함

### Pathfinder / Path-X
- Pathfinder: 평균 72%, Performer 77.05%
- Path-X: 모든 모델이 50% 이하 (랜덤 수준)

### Result

- 결론: 만능 모델은 없음
- BigBird는 가장 **일관된 성능** 으로 평균 성능 가장 우수
- Performer, Linformer는 **빠르고 가볍지만** ListOps 성능 때문에 평균 성능 낮음

![figure3](/asset/img/lra/figure3.jpg)
x축: 속도, y축: 성능, 원의 크기: 메모리 사용량  
Performer, Linformer, Linear Transformer는 합리적인 메모리 사용을 유지하면서 속도 및 성능 측면에서 좋은 모델임
---

## 데이터셋 다운로드 방법

> 공식 가이드: [https://github.com/google-research/long-range-arena#dataset-setup](https://github.com/google-research/long-range-arena#dataset-setup)
> ![datasetup](/asset/img/lra/datasetup.jpg)

### lra_release

- `tsv_data/` → AAN (3개의 TSV)
- `listops-1000/` → ListOps
- `pathfinder32/128/256/` → Pathfinder 계열
- IMDB, CIFAR-10은 TFDS(Tensorflow dataset)에서 자동 다운로드가 가능하므로 별도로 다운받지 않아도 됨

> `.gz` 압축파일 기준 약 7.7GB

### Folder config

```text
listops-1000/
├── basic_train.tsv (60,000)
├── basic_val.tsv (2,000)
└── basic_test.tsv (2,000)

![listops-1000 folder](/asset/img/lra/listops_folder.jpg)

tsv_data/
├── new_aan_pairs.train.tsv
├── new_aan_pairs.eval.tsv
└── new_aan_pairs.test.tsv

![aan folder](/asset/img/lra/aan_folder.jpg)
