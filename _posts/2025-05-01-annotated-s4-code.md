---
title: "[Annotated-S4] ì½”ë“œ ì‹¤í–‰ ë°©ë²• ë° ì½”ë“œ ë¦¬ë·°"
date: 2025-05-01 21:00:00 +0900
description: "ë³¸ ê¸€ì€ https://github.com/srush/annotated-s4ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ëœ ê¸€ì…ë‹ˆë‹¤."
math: true
image:
  path: /assets/img/favicons/favicon-96x96.png
  alt: "S4"
categories: [code]
tags: [SSM, S4, Annotated-S4, Docker, JAX,]
---

> ë³¸ ê¸€ì€ Annotated-S4([ë§í¬](https://srush.github.io/annotated-s4/))ì˜ ì½”ë“œ ì‹¤í–‰ ë°©ë²•ê³¼ í•µì‹¬ íŒŒì¼ì„ ì„¤ëª…í•˜ëŠ” ê¸€ì…ë‹ˆë‹¤.

---

[Annotated S4](https://github.com/srush/annotated-s4)ëŠ” Structured State Space ëª¨ë¸(S4)ì„ êµ¬í˜„í•œ JAX/Flax ê¸°ë°˜ ì½”ë“œì…ë‹ˆë‹¤.  
ì´ ê¸€ì—ì„œëŠ” í•´ë‹¹ ì½”ë“œë¥¼ ë¡œì»¬ ë˜ëŠ” Docker í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ë°©ë²•ê³¼, ì£¼ìš” êµ¬ì„± íŒŒì¼ì¸ `s4.py`, `train.py`ì— ëŒ€í•œ êµ¬ì¡° ë° ì—­í• ì„ ì •ë¦¬í•©ë‹ˆë‹¤.

---

## ì½”ë“œ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜

### ì‚¬ì „ ì¤€ë¹„

- **Docker ì‚¬ìš©**:
  - [pytorch/pytorch:1.13.1-cuda11.6-cudnn8-devel](https://hub.docker.com/r/pytorch/pytorch/) ê¸°ë°˜ ì´ë¯¸ì§€ ì¶”ì²œ
  - GPU ì‚¬ìš© ê°€ëŠ¥ í™˜ê²½ í•„ìš” (e.g. NVIDIA Container Toolkit)
  - ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì‹œ: `/workspace` ë””ë ‰í† ë¦¬ ìƒì„±, `--gpus all` í”Œë˜ê·¸ ì‚¬ìš©

- **Local (Conda í™˜ê²½) ì‚¬ìš©**:
  ```bash
  conda create -n s4_env python=3.10
  conda activate s4_env
	```

### ğŸ”½ ì½”ë“œ í´ë¡  ë° ë””ë ‰í† ë¦¬ ì´ë™

Annotated-S4 ì €ì¥ì†Œë¥¼ í´ë¡ í•œ í›„, ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•©ë‹ˆë‹¤:

```bash
git clone https://github.com/srush/annotated-s4.git
cd annotated-s4
```

### ì˜ì¡´ì„± ì„¤ì¹˜

ì´ [requirements.txt](/assets/data/s4/annotated-s4.txt)ëŠ” í•˜ë‚˜ì˜ ì˜ˆì‹œì´ë¯€ë¡œ ì‹¤ì œ ì‚¬ìš© ì‹œ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

#### ì‹¤í–‰ ì˜ˆì‹œ
MNIST Classification
```bash
python -m s4.train dataset=mnist layer=s4 train.epochs=100 train.bsz=128 model.d_model=128 model.layer.N=64
CIFAR Classification
```

```bash
python -m s4.train dataset=cifar-classification layer=s4d train.epochs=100 train.bsz=50 model.n_layers=6 model.d_model=512 model.dropout=0.25 train.lr=5e-3 train.weight_decay=0.01 train.lr_schedule=true seed=1 +model.layer.scaling=linear
```
### ğŸ“‚ LRA Dataset Mount

LRA dataset ì¤‘ Annotated-s4ê°€ ê¸°ë³¸ìœ¼ë¡œ ì œê³µí•˜ëŠ” ê²ƒì€ MNIST Classification, CIFAR-10 Classification ì…ë‹ˆë‹¤. listops, aan, pathfinderë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•´ì„œëŠ” [LRA ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì„ ë‹¤ìš´](https://namaewa-im.github.io/posts/lra/#how-to-download-dataset)ë°›ì•„ì•¼í•©ë‹ˆë‹¤.

LRA ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì„ ë¡œì»¬ ë˜ëŠ” Docker í™˜ê²½ì— ë§ˆìš´íŠ¸í•©ë‹ˆë‹¤:

#### ë‹¤ìš´ë°›ì„ ë¡œì»¬ ìœ„ì¹˜
~/Downloads/lra_release/lra_release

#### Docker ì‹¤í–‰ ì½”ë“œ
```bash
docker run -it --gpus all -v ~/Downloads/lra_release/lra_release:/workspace/lra_release <image>:<tag> bash
```
ë°ì´í„°ì…‹ì´ ì €ì¥ë˜ëŠ” ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ê²½ë¡œëŠ” /workspace/lra_releaseì…ë‹ˆë‹¤.

#### ì‹¤í–‰ ì˜ˆì‹œ
```bash
python -m train dataset=listops-classification +dataset.data_dir=/workspace/lra_release/listops-1000
``` 

#### imdb
```bash
TypeError: An invalid dataloader was returned from SequenceLightningModule.val_dataloader(). Found None.
```
í•´ê²° ë°©ë²•: dataset configì—ì„œ val_split: 0.1ë¡œ ìˆ˜ì •

#### Pathfinder, Path-X, AAN
Pathfinder, Path-X, AANëŠ” annotated-s4/s4/data.pyì—ì„œ ë”°ë¡œ ì œê³µí•˜ê³  ìˆì§€ ì•Šê¸° ë•Œë¬¸ì— í•´ë‹¹ ì½”ë“œë¡œ í•™ìŠµì„ ëŒë¦¬ê¸° ìœ„í•´ì„œëŠ” create_{pathfinder, pathx, aan}_dataset()ì„ ì§ì ‘ ë§Œë“¤ì–´ì•¼í•©ë‹ˆë‹¤. 

ë‹¤ìŒì€ create_pathfinder_dataset()ì˜ ì˜ˆì‹œì…ë‹ˆë‹¤. annotated-s4/s4/data.py ì•„ë˜ì— ë‹¤ìŒê³¼ ê°™ì´ ì‘ì„±í•©ë‹ˆë‹¤:

```python
def create_pathfinder_dataset(bsz=128, n_workers=2):
    import os
    import numpy as np
    import torch
    from torch.utils.data import Dataset, DataLoader, random_split
    from torchvision import transforms
    from PIL import Image
    from pathlib import Path

    blacklist = {"/workspace/lra_release/pathfinder32/curv_baseline/imgs/0/sample_172.png"} # empty data

    base_path = "/workspace/lra_release/pathfinder32/curv_baseline"
    metadata_path = os.path.join(base_path, "metadata")
    imgs_base_path = os.path.join(base_path, "imgs")

    print(f"Loading Pathfinder32 from {base_path}")

    # Step 1: ë©”íƒ€ë°ì´í„° íŒŒì‹±
    samples = []
    for fname in sorted(os.listdir(metadata_path), key=lambda f: int(f.split('.')[0])):
        with open(os.path.join(metadata_path, fname), "r") as f:
            for line in f:
                parts = line.strip().split()
                img_dir = parts[0]      # e.g. imgs/0
                img_file = parts[1]     # e.g. sample_0.png
                label = int(parts[3])   # 0 or 1
                img_path = os.path.join(base_path, img_dir, img_file)

                # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì²´í¬
                if img_path in blacklist:
                    continue
                
                samples.append((img_path, label))

    # [Debug] í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
    print("\n[Debug] Class Distribution:")
    unique_labels, counts = np.unique([s[1] for s in samples], return_counts=True)
    for label, count in zip(unique_labels, counts):
        print(f"Class {label}: {count} samples ({count/len(samples)*100:.2f}%)")

    # Step 2: Dataset ì •ì˜
    class PathfinderDataset(Dataset):
        def __init__(self, samples):
            self.samples = samples
            self.transform = transforms.Compose([
                transforms.Grayscale(),
                transforms.Resize((32, 32)),
                transforms.ToTensor(),                  # (1, 32, 32)
                transforms.Lambda(lambda x: x.view(-1, 1))  # Flatten to (1024, 1)
            ])

        def __len__(self):
            return len(self.samples)

        def __getitem__(self, idx):
            img_path, label = self.samples[idx]
            img = Image.open(img_path).convert("L")
            img = self.transform(img)
            return img, torch.tensor(label, dtype=torch.long)

    # Step 3: train/val/test split
    full_dataset = PathfinderDataset(samples)
    
    # [Debug] ë°ì´í„°ì…‹ ìƒ˜í”Œ í™•ì¸
    print("\n[Debug] Dataset Sample Check:")
    sample_img, sample_label = full_dataset[0]
    print(f"Sample image shape: {sample_img.shape}")
    print(f"Sample label: {sample_label}")
    print(f"Sample image min/max: {sample_img.min()}, {sample_img.max()}")
    print(f"Sample image mean/std: {sample_img.mean()}, {sample_img.std()}")
    
    val_len = int(0.1 * len(full_dataset))
    test_len = int(0.1 * len(full_dataset))
    train_len = len(full_dataset) - val_len - test_len
    train_set, val_set, test_set = random_split(full_dataset, [train_len, val_len, test_len], generator=torch.Generator().manual_seed(42))

    # [Debug] ë°ì´í„°ì…‹ í¬ê¸° í™•ì¸
    print("\n[Debug] Dataset Sizes:")
    print(f"Train set size: {len(train_set)}")
    print(f"Validation set size: {len(val_set)}")
    print(f"Test set size: {len(test_set)}")

    # Step 4: DataLoader êµ¬ì„±
    trainloader = DataLoader(train_set, batch_size=bsz, shuffle=True, num_workers=n_workers, pin_memory=True)
    testloader = DataLoader(test_set, batch_size=bsz, shuffle=False, num_workers=n_workers, pin_memory=True)

    # [Debug] DataLoader ìƒ˜í”Œ í™•ì¸
    print("\n[Debug] DataLoader Sample Check:")
    train_batch = next(iter(trainloader))
    print(f"Train batch images shape: {train_batch[0].shape}")
    print(f"Train batch labels shape: {train_batch[1].shape}")
    print(f"Train batch labels: {train_batch[1][:5]}")  # ì²« 5ê°œ ë¼ë²¨ ì¶œë ¥

    SEQ_LENGTH = 32 * 32
    IN_DIM = 1
    N_CLASSES = 2

    return trainloader, testloader, N_CLASSES, SEQ_LENGTH, IN_DIM


Datasets = {
    "mnist": create_mnist_dataset,
    "quickdraw": create_quickdraw_dataset,
    "fsdd": create_fsdd_dataset,
    "sc": create_sc_dataset,
    "sin": create_sin_x_dataset,
    "sin_noise": create_sin_ax_b_dataset,
    "mnist-classification": create_mnist_classification_dataset,
    "fsdd-classification": create_fsdd_classification_dataset,
    "cifar-classification": create_cifar_classification_dataset,
    "imdb-classification": create_imdb_classification_dataset,
    "listops-classification": create_listops_classification_dataset,
    "pathfinder": create_pathfinder_dataset, # ë°ì´í„°ì…‹ ì¶”ê°€
}

```

ë‹¤ìŒì„ ì‹¤í–‰í•˜ì—¬ ì½”ë“œê°€ ë™ì‘í•˜ëŠ” ì§€ í™•ì¸í•©ë‹ˆë‹¤:
```bash
python -m train dataset=pathfinder
``` 


### ê²°ê³¼ ì‹œê°í™”
wandbë¥¼ ì‚¬ìš©í•´ í•™ìŠµ ê³¼ì •ì„ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. wandb ì•„ì´ë””ë¥¼ ë§Œë“  ë‹¤ìŒ ì„¤ì¹˜ ë° í„°ë¯¸ë„ ì°½ì—ì„œì˜ ë¡œê·¸ì¸ ë° initì„ ì‹¤í–‰í•©ë‹ˆë‹¤:
```bash
pip install wandb
wandb login
wandb init
```
ê·¸ í›„ ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤:
```bash
python -m s4.train dataset=listops-classification wandb.mode=online wandb.project=annotated-s4
```
train.py ì‹¤í–‰ ì‹œ ë¡œê·¸ì¸í•œ ê³„ì •ì— ìë™ìœ¼ë¡œ ë¡œê¹…ë˜ì–´ ì‹¤ì‹œê°„ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

#### ListOps
![listops](/assets/img/annotated-s4/listops1.webp)

#### IMDb
![imdb](/assets/img/annotated-s4/imdb1.webp)

#### Cifar-10
![cifar10](/assets/img/annotated-s4/cifar1.webp)

#### Pathfinder
![pathfinder](/assets/img/annotated-s4/pathfinder1.webp)


## ì½”ë“œ êµ¬ì¡° ë¦¬ë·°
Annotated-S4 ì½”ë“œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ë‘ íŒŒì¼ì¸ [s4.py]()ì™€ [train.py]()ì˜ êµ¬ì¡°ì™€ ì‘ë™ ë°©ì‹ì„ ì‚´í´ë´…ë‹ˆë‹¤.

### s4.py

s4.pyëŠ” 3ê°œì˜ ì£¼ìš” ì¸µìœ„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

#### 1. ì´ë¡  êµ¬í˜„ ë ˆë²¨ - SSMì˜ ê¸°ë³¸ ì—°ì‚°
**random_SSM(rng, N):** A, B, C ìƒì„±  
**discretize(A, B, C, step):** Ab, Bb, C  
**scan_SSM(Ab, Bb, Cb, u, x0):** recurrence ì²˜ë¦¬  
**run_SSM(A, B, C, u):** ì „ì²´ ì‹œí€€ìŠ¤ ì²˜ë¦¬  

#### 2. ì‹ í˜¸ ì²˜ë¦¬ ë ˆë²¨ - SSMì„ convolution ì»¤ë„ë¡œ ë³€í™˜
**K_conv(Ab, Bb, Cb, L):** ì»¤ë„ ìƒì„±  
**causal_convolution(u, K):** ì»¨ë³¼ë£¨ì…˜ ê³„ì‚°  
**K_gen_DPLR(...), kernel_DPLR(...):** DPLR ê¸°ë°˜ ì»¤ë„ ìƒì„±  
**discrete_DPLR(...):** RNNìš© ì»¤ë„ ì´ì‚°í™”  

#### 3. Neural Network ë ˆë²¨ - S4ë¥¼ Flax ëª¨ë¸ë¡œ í†µí•©

**S4Layer:** CNN ë˜ëŠ” RNN ëª¨ë“œ ì§€ì›í•˜ëŠ” í•µì‹¬ ë ˆì´ì–´  
**cloneLayer:** Hê°œì˜ S4Layer ë³µì œ ì§€ì›  
**SequenceBlock:** S4Layer + Dropout + Denseë¥¼ ë¬¶ì€ ë¸”ë¡  
**StackedModel:** ì—¬ëŸ¬ ë ˆì´ì–´ë¥¼ ìŒ“ê³ , encoder/decoder êµ¬ì„±  
**BatchStackedModel:** ë°°ì¹˜ ë‹¨ìœ„ ì²˜ë¦¬  


### s4.py ëª¨ë“ˆ ì…ì¶œë ¥ êµ¬ì¡°

#### 1. ì´ë¡  êµ¬í˜„ ë ˆë²¨
##### 1-1. random_SSM
```
input: rng, N
return: A, B, C
```
##### 1-2. discretize
```
input: A, B, C, step
return: Ab, Bb, C
```
##### 1-3. scan_SSM
```
input: Ab, Bb, Cb, u, x0
return: jax.lax.scan(step, x0, u)
```
###### 1-3-1. step
```
input: x_k_1, u_k
return x_k, y_k
```
##### 1-4. run_SSM
```
input: A, B, C, u
return: y
```

#### 2. ì‹ í˜¸ ì²˜ë¦¬ ë ˆë²¨
##### 2-1. K_conv
```
input: Ab, Bb, Cb, L
return: K
```
##### 2-2. causal_convolution
```
input: u, K
return: y 
```
##### 2-3. K_gen_DPLR
```
input: Lamdba, P, Q, B, C, step
return: gen
```
###### 2-3-1. cauchy_dot
```
input: a, g, Lambda
out: gen
```
##### 2-4. kernel_DPLR
```
input: Lambda, P, Q, B, C, step, L
return: y.real
```

##### 2-5. discrete_DPLR
```
input: Lambda, P, Q, B, C, step, L
return: Ab, Bb, Cb.conj()
```

#### 3. Neural Network ë ˆë²¨
##### 3-1. SSMLayer
```
setup: A, B, C, D, log_step, ssm, k, x_k_1
call: if not decode: causal_convolution(u,k)+D*u
else: scan_SSMìœ¼ë¡œ y_s.real+D*u
```
##### 3-2. cloneLayer
SSMLayerë‚˜ S4Layerë¥¼ layer dim Hê°œë¡œ ë³µì œ

##### 3-3. SequenceBlock
```
setup: seq, layer_cls, norm, out, glu, out2, drop, ...
call: norm-> seq->drop-> glu-> skip+dorp-> norm
```
##### 3-4. StackedModel
```
setup: encoder if embedding: Embedding else: Dense
decoder, layers = (SequenceBlock())
call: classfication if embedding: embedding else: decode
encoder-> layer-> decoder-> log_softmax
```
##### 3-5. BatchStakedModel
ë°°ì¹˜ì‚¬ì´ì¦ˆ Bê°œë¡œ ë³µì œ

##### 3-6. S4Layer
```
setup: Lambda_re, Lambda_im, Lambda, P, B, C, D, step
if not decode: K else: discrete_DPLR
call: if not decode: causal_convolution else: scan_SSM
```
### train.py

#### train.py êµ¬ì¡°
ëª¨ë¸ í•™ìŠµê³¼ í‰ê°€ë¥¼ ìœ„í•œ ë£¨í‹´ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

**create_train_state()**: ëª¨ë¸ ì´ˆê¸°í™” ë° ì˜µí‹°ë§ˆì´ì € êµ¬ì„±  
**train_epoch()**: 1 epoch í•™ìŠµ ë£¨í”„ ìˆ˜í–‰  
**validate()**: ê²€ì¦ ë£¨í”„ ìˆ˜í–‰  
**train_step() / eval_step()**: JIT ê¸°ë°˜ 1 step í•™ìŠµ/ê²€ì¦ ì²˜ë¦¬  
**example_train()**: ì „ì²´ í•™ìŠµ ê³¼ì • ì¡°ë¦½ ë° ìˆ˜í–‰  

#### train.py ëª¨ë“ˆ ì…ì¶œë ¥
##### 1. create_train_state: ëª¨ë¸ íŒŒë¼ë¯¸í„° ì´ˆê¸°í™” ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
```
input: rng, model_cls, trainloader, lr, lr_layer, lr_schedule, weight_decay, total_steps=1
return: flax.training.train_state.TrainState(model.apply, params, tx)
```
##### 2. train_epoch: ì—í­ ë‹¨ìœ„ í•™ìŠµ
```
input: state, rng, model, trainloader, classification=False
return: state, batch_losses, batch_accuracies
```
##### 3. validate: ì—í­ ë‹¨ìœ„ ê²€ì¦
```
input: params, model, testloader, classification=False
return: loss, acc
```
##### 4. train_step: @partial(jax.jit, static_argnums=(4,5))
```
input: state, rng, batch_inputs, batch_labels, model, classification=False 
return: state, loss, acc
```
##### 5. eval_step: @partial(jax.jit, static_argnums=(3,4))
```
input: batch_input, batch_labels, params, model, classification=False
return: loss, acc
```
##### 6. example_train: 
```
input: dataset, layer, seed, model_cfg, train_cfg
return: None
```

###### example_trainì˜ ì…ì¶œë ¥/ì½”ë“œ íë¦„

**ì…ë ¥:** Hydraë¡œë¶€í„° ë°›ì€ cfg: DictConfig  
**ì¶œë ¥:** None(ëª¨ë¸ í•™ìŠµ ë° wandb logging, checkpoint ì €ì¥)

[init]  
    - torch/jax random seed ì„¤ì •  
    - ë°ì´í„°ì…‹ ë¡œë”© (Datasets[dataset])  
    - ëª¨ë¸ í´ë˜ìŠ¤ ê²°ì • (Models[layer])  
    - ëª¨ë¸ ì„¤ì • ê°’ ìˆ˜ì • (model.layer.l_max ë“±)  
    - ëª¨ë¸ partial ìƒì„± (BatchStackedModel(layer_cls, ...))  

[Model init]  
    - create_train_state()ë¡œ íŒŒë¼ë¯¸í„° ì´ˆê¸°í™” + ì˜µí‹°ë§ˆì´ì € ì„¤ì •

[epoch loop]  
for epoch:  
    - train_epoch() í˜¸ì¶œ â†’ train_step ë°˜ë³µ  
    - validate() í˜¸ì¶œ â†’ eval_step ë°˜ë³µ  
    - wandb log, checkpoint ì €ì¥, ìƒ˜í”Œë§ ìˆ˜í–‰  

#### ì „ì²´ ì½”ë“œ íë¦„
config.yaml -> main() -> example_train() -> create_train_state() -> train_epoch() -> validate()
