---
title: "LRA: 긴 시퀀스를 위한 벤치마크 소개"
date: 2025-04-14 23:00:00 +0900
categories: [Benchmark, Sequence]
tags: [lra, sequence-modeling, long-range]
pin: true
image: /assets/img/lra/lra-logo.png  
description: "Transformer를 넘어서기 위한 시도, LRA 벤치마크의 구조와 의의를 정리합니다."
---

## LRA란?

**LRA (Long Range Arena)** 는 긴 시퀀스를 다루는 모델의 성능을 비교하기 위해 고안된 **딥러닝 벤치마크**입니다.  
Transformer와 같은 기존 sequence 모델들은 **긴 입력 길이**를 처리할 때 성능과 효율성에서 큰 한계를 보이곤 했죠.

LRA는 이러한 **"long-range dependency"** 문제를 해결할 수 있는 새로운 아키텍처들을 시험할 수 있도록 다음과 같은 특징을 가집니다:

---

## 주요 특징

- **길이**: 입력 시퀀스는 1k~16k tokens 수준
- **다양한 도메인**:
  - 텍스트 분류 (IMDB)
  - 구조 추론 (ListOps)
  - 이미지 분류 (CIFAR-10)
  - 문서 유사도 판단 (Byte-level Retrieval)
- **통일된 비교 기준**:
  - 동일한 하이퍼파라미터, 동일한 학습 시간, 동일한 환경
- **효율성과 정확도 동시 평가**:
  - 모델의 **계산량**, **파라미터 수**, **성능**을 모두 측정

---

## 사용 이유

내가 이 벤치마크에 주목한 이유는 간단하다:

> **단순히 정확도가 높은 모델이 아니라, 효율적으로 "긴 문맥"을 이해하는 모델을 만들고 싶기 때문.**

Transformer는 강력하지만, 계산량이 Quadratic.  
이에 반해 S4, Mamba, 그리고 다양한 SSM(State Space Model) 기반 모델들은 LRA를 통해 **실제로 “길이에 강한”지**를 검증받는다.

---

## 대표 태스크: ListOps

가장 재미있는 태스크 중 하나는 **ListOps**다.

- 문자열 형태의 수식 → 숫자 출력
- 간단해 보이지만, **계층적 연산과 긴 의존성**이 필요한 구조
- RNN이나 CNN은 이 구조를 **거의 못 풀지만**,  
  **SSM 기반 모델들은 이걸 잘 푼다!**

---

## 나의 실험 목표

앞으로 이 블로그에서는:

LRA 각 태스크에 대한 실험 기록



---

## 참고 자료

- [LRA Official GitHub](https://github.com/google-research/long-range-arena)
- [S4 논문 (ICLR 2022)](https://arxiv.org/abs/2111.00396)
- [Mamba (2023)](https://arxiv.org/abs/2312.00752)

---

> 긴 시퀀스를 더 똑똑하게 처리하는 것,  
> 그게 바로 우리가 다음 세대 모델을 향해 가는 길이다. 🧠
